{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import read\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import timedelta\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, ConfusionMatrixDisplay\n",
    "\n",
    "# Set device to CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Directory paths\n",
    "lunar_catalog_path = '../../data/lunar_data/training/catalogs/apollo12_catalog_GradeA_final.csv'\n",
    "lunar_data_directory = '../../data/lunar_data/training/data/S12_GradeA/'\n",
    "martian_data_directory = '../../data/marsquake_data/training/data/'\n",
    "lunar_data_images_dir = '../../model/model_output/lunar_preprocessed_images/'\n",
    "martian_data_images_dir = '../../model/model_output/martian_preprocessed_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def convert_rel_to_abs_time(start_time, time_rel):\n",
    "    return (start_time + timedelta(seconds=float(time_rel))).strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "def apply_bandpass_filter(trace, sampling_rate, freqmin=0.5, freqmax=3.0):\n",
    "    sos = signal.butter(4, [freqmin, freqmax], btype='bandpass', fs=sampling_rate, output='sos')\n",
    "    return signal.sosfilt(sos, trace)\n",
    "\n",
    "def load_existing_images(image_dir):\n",
    "    image_files = [os.path.join(root, file) for root, _, files in os.walk(image_dir) for file in files if file.endswith('.png')]\n",
    "    return image_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Functions\n",
    "def preprocess_lunar_data(lunar_data_directory):\n",
    "    lunar_images = load_existing_images(lunar_data_directory)\n",
    "    print(f\"{len(lunar_images)} lunar images loaded.\")\n",
    "    return lunar_images\n",
    "\n",
    "def preprocess_martian_data(data_dir, save_dir, combine_images=True):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    martian_images, martian_arrival_times = [], []\n",
    "    mseed_files = [f for f in os.listdir(data_dir) if f.endswith('.mseed')]\n",
    "\n",
    "    if len(mseed_files) == 0:\n",
    "        print(\"No .mseed files found in the directory.\")\n",
    "        return martian_images, martian_arrival_times\n",
    "\n",
    "    for filename in mseed_files:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        csv_file_path = file_path.replace('.mseed', '.csv')\n",
    "\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            print(f\"CSV file not found for {filename}: {csv_file_path}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            csv_data = pd.read_csv(csv_file_path)\n",
    "            arrival_time_rel = csv_data['rel_time(sec)'].iloc[0]\n",
    "            image_path = plot_and_save_trace_spectrogram(file_path, arrival_time_rel, save_dir, filename, combine_images)\n",
    "            martian_images.append(image_path)\n",
    "            martian_arrival_times.append(arrival_time_rel)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    return martian_images, martian_arrival_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Definition\n",
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectrogramCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 112 * 112, 128) #edit to None if it doesn't work\n",
    "        self.fc_event = nn.Linear(128, 3)\n",
    "        self.fc_time = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.size(1), 128)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc_event(x), self.fc_time(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def prepare_data_for_training(image_files, labels, time_labels, batch_size=32):\n",
    "    if not image_files:\n",
    "        return None  # Early exit if no images are provided\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    image_tensors = [transform(Image.open(img)) for img in image_files if os.path.exists(img) and img.endswith('.png')]\n",
    "    if image_tensors:\n",
    "        X_tensor = torch.stack(image_tensors)\n",
    "        y_event_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        y_time_tensor = torch.tensor(time_labels, dtype=torch.float32)\n",
    "        dataset = TensorDataset(X_tensor, y_event_tensor, y_time_tensor)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return None\n",
    "\n",
    "# Training Functions\n",
    "def train_model(model, train_loader, criterion_event, criterion_time, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, event_labels, time_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            event_output, time_output = model(inputs)\n",
    "            loss_event = criterion_event(event_output, event_labels)\n",
    "            loss_time = criterion_time(time_output.squeeze(), time_labels)\n",
    "            loss = loss_event + loss_time\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "def self_train_on_martian_data(model, martian_data_loader, optimizer, criterion_event, criterion_time, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch in martian_data_loader:\n",
    "            images = batch[0]  # Unpack the images from the batch tuple\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the model\n",
    "            event_output, time_output = model(images)\n",
    "\n",
    "            # Generate pseudo-labels (predicted event labels)\n",
    "            _, pseudo_labels = torch.max(event_output, 1)\n",
    "\n",
    "            # For now, we do not have ground truth for Martian data, so we only optimize on pseudo-labels\n",
    "            loss_event = criterion_event(event_output, pseudo_labels)\n",
    "            loss_time = criterion_time(time_output.squeeze(), torch.zeros_like(time_output.squeeze()))  # Use zeros as placeholder\n",
    "\n",
    "            # Calculate total loss and perform backpropagation\n",
    "            total_loss = loss_event + loss_time\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "\n",
    "        print(f\"Self-training Epoch {epoch+1}, Loss: {running_loss/len(martian_data_loader)}\")\n",
    "\n",
    "# Model Evaluation\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    event_preds, time_preds, event_true, time_true = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, event_labels, time_labels in data_loader:\n",
    "            event_output, time_output = model(images)\n",
    "            _, event_pred_classes = torch.max(event_output, 1)\n",
    "            event_preds.extend(event_pred_classes.cpu().numpy())\n",
    "            time_preds.extend(time_output.cpu().numpy())\n",
    "            event_true.extend(event_labels.cpu().numpy())\n",
    "            time_true.extend(time_labels.cpu().numpy())\n",
    "    event_accuracy = accuracy_score(event_true, event_preds)\n",
    "    time_mae = mean_absolute_error(time_true, time_preds)\n",
    "    print(f\"Validation Event Accuracy: {event_accuracy:.4f}\")\n",
    "    print(f\"Validation Time MAE: {time_mae:.4f}\")\n",
    "    ConfusionMatrixDisplay.from_predictions(event_true, event_preds)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Save Function\n",
    "def save_model_artifacts(model, model_name='seismic_cnn_model'):\n",
    "    model_architecture = {\n",
    "        'conv_layers': [{'in_channels': model.conv1.in_channels, 'out_channels': model.conv1.out_channels, 'kernel_size': model.conv1.kernel_size},\n",
    "                        {'in_channels': model.conv2.in_channels, 'out_channels': model.conv2.out_channels, 'kernel_size': model.conv2.kernel_size}],\n",
    "        'fc_layers': [{'in_features': model.fc_event.in_features, 'out_features': model.fc_event.out_features},\n",
    "                      {'in_features': model.fc_time.in_features, 'out_features': model.fc_time.out_features}]\n",
    "    }\n",
    "    with open(f'{model_name}_architecture.json', 'w') as f:\n",
    "        json.dump(model_architecture, f, indent=4)\n",
    "    torch.save(model.state_dict(), f'{model_name}_weights.pth')\n",
    "    torch.save(model, f'{model_name}_full.pth')\n",
    "    print(f\"Model saved to {model_name}_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_image_list(image_list):\n",
    "    \"\"\"\n",
    "    Ensure image list is flat in case there are nested lists of image paths.\n",
    "    \"\"\"\n",
    "    if isinstance(image_list, (list, tuple)) and any(isinstance(i, (list, tuple)) for i in image_list):\n",
    "        return [item for sublist in image_list for item in sublist]\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_unlabeled_data_loader(image_files, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    image_tensors = [transform(Image.open(img)) for img in image_files if os.path.exists(img) and img.endswith('.png')]\n",
    "    if image_tensors:\n",
    "        X_tensor = torch.stack(image_tensors)\n",
    "        dataset = TensorDataset(X_tensor)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the paths for preprocessed images\n",
    "    lunar_data_images_dir = '../../model/model_output/lunar_preprocessed_images/'\n",
    "    martian_data_images_dir = '../../model/model_output/martian_preprocessed_images/'\n",
    "    save_dir = martian_data_images_dir  # Directory where Martian images are saved\n",
    "\n",
    "    # 1. Load pre-generated lunar images\n",
    "    print(f\"Loading pre-generated lunar data from: {lunar_data_images_dir}\")\n",
    "    lunar_images = preprocess_lunar_data(lunar_data_images_dir)\n",
    "\n",
    "    # Check if any lunar images were loaded\n",
    "    if not lunar_images:\n",
    "        print(\"Error: No lunar images found. Exiting.\")\n",
    "        return  # Exit early if no images found\n",
    "\n",
    "    lunar_labels = [0] * len(lunar_images)  # Placeholder labels for lunar data\n",
    "    lunar_times = [0] * len(lunar_images)   # Placeholder arrival times for lunar data\n",
    "\n",
    "    # Prepare DataLoader for lunar data\n",
    "    print(\"Preparing DataLoader for lunar data...\")\n",
    "    train_loader = prepare_data_for_training(lunar_images, lunar_labels, lunar_times)\n",
    "\n",
    "    if train_loader is None:\n",
    "        print(\"Error: No valid data for training. DataLoader creation failed.\")\n",
    "        return  # Exit early if DataLoader creation failed\n",
    "\n",
    "    # 2. Initialize and train the model on lunar data\n",
    "    print(\"Initializing SpectrogramCNN model...\")\n",
    "    model = SpectrogramCNN()\n",
    "    criterion_event = nn.CrossEntropyLoss()\n",
    "    criterion_time = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    print(\"Training model on lunar data...\")\n",
    "    train_model(model, train_loader, criterion_event, criterion_time, optimizer)\n",
    "\n",
    "    # 3. Load pre-generated Martian images\n",
    "    print(f\"Loading pre-generated Martian data from: {martian_data_images_dir}\")\n",
    "    martian_images = load_existing_images(martian_data_images_dir)  # Load images directly\n",
    "\n",
    "    # Check if any Martian images were loaded\n",
    "    if not martian_images:\n",
    "        print(\"Error: No Martian images found. Exiting.\")\n",
    "        return  # Exit early if no images found\n",
    "\n",
    "    # Prepare DataLoader for Martian data\n",
    "    print(\"Preparing DataLoader for Martian data...\")\n",
    "    martian_data_loader = prepare_unlabeled_data_loader(martian_images)\n",
    "\n",
    "    if martian_data_loader is None:\n",
    "        print(\"Error: No valid data for self-training. DataLoader creation failed.\")\n",
    "        return  # Exit early if DataLoader creation failed\n",
    "\n",
    "    # 4. Self-train the model on Martian data\n",
    "    print(\"Self-training model on Martian data...\")\n",
    "    self_train_on_martian_data(model, martian_data_loader, optimizer, criterion_event, criterion_time)\n",
    "\n",
    "    # 5. Save the fine-tuned model\n",
    "    print(\"Saving the fine-tuned model...\")\n",
    "    save_model_artifacts(model, model_name='../../model/fine_tuned_martian_seismic_cnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-generated lunar data from: ../../model/model_output/lunar_preprocessed_images/\n",
      "76 lunar images loaded.\n",
      "Preparing DataLoader for lunar data...\n",
      "Initializing SpectrogramCNN model...\n",
      "Training model on lunar data...\n",
      "Epoch 1, Loss: 1600.0661470890045\n",
      "Epoch 2, Loss: 449.5803413391113\n",
      "Epoch 3, Loss: 195.09067153930664\n",
      "Epoch 4, Loss: 3.13076926022768\n",
      "Epoch 5, Loss: 0.5083693067232767\n",
      "Epoch 6, Loss: 0.670348584651947\n",
      "Epoch 7, Loss: 0.8254997730255127\n",
      "Epoch 8, Loss: 0.9365084966023763\n",
      "Epoch 9, Loss: 0.9263431032498678\n",
      "Epoch 10, Loss: 0.9064249992370605\n",
      "Loading pre-generated Martian data from: ../../model/model_output/martian_preprocessed_images/\n",
      "Preparing DataLoader for Martian data...\n",
      "Self-training model on Martian data...\n",
      "Self-training Epoch 1, Loss: 0.8976970314979553\n",
      "Self-training Epoch 2, Loss: 0.889222264289856\n",
      "Self-training Epoch 3, Loss: 0.8802964687347412\n",
      "Self-training Epoch 4, Loss: 0.8709366917610168\n",
      "Self-training Epoch 5, Loss: 0.8611681461334229\n",
      "Self-training Epoch 6, Loss: 0.8509337902069092\n",
      "Self-training Epoch 7, Loss: 0.840172529220581\n",
      "Self-training Epoch 8, Loss: 0.828025221824646\n",
      "Self-training Epoch 9, Loss: 0.8153128623962402\n",
      "Self-training Epoch 10, Loss: 0.8020918369293213\n",
      "Saving the fine-tuned model...\n",
      "Model saved to ../../model/fine_tuned_martian_seismic_cnn_full.pth\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(model_path):\n",
    "    \"\"\"\n",
    "    Load the trained model from the specified path.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the saved model file.\n",
    "\n",
    "    Returns:\n",
    "        model (nn.Module): Loaded PyTorch model.\n",
    "    \"\"\"\n",
    "    model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_data(model, test_folders):\n",
    "    \"\"\"\n",
    "    Iterate over test folders, make predictions, and collect results.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained model.\n",
    "        test_folders (list): List of paths to test data directories.\n",
    "\n",
    "    Returns:\n",
    "        results (list): List of dictionaries containing predictions and file information.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    for folder in test_folders:\n",
    "        print(f\"Processing folder: {folder}\")\n",
    "        image_files = load_existing_images(folder)\n",
    "        if not image_files:\n",
    "            print(f\"No images found in folder: {folder}\")\n",
    "            continue\n",
    "        for img_path in image_files:\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "            with torch.no_grad():\n",
    "                event_output, time_output = model(img_tensor)\n",
    "                _, event_pred_class = torch.max(event_output, 1)\n",
    "                rel_time_pred = time_output.item()\n",
    "                \n",
    "            # Extract filename\n",
    "            filename = os.path.basename(img_path)\n",
    "            # Collect results\n",
    "            result = {\n",
    "                'folder': folder,\n",
    "                'filename': filename,\n",
    "                'event_class_pred': event_pred_class.item(),\n",
    "                'rel_time_pred': rel_time_pred\n",
    "            }\n",
    "            # Attempt to load ground truth labels if available\n",
    "            label_csv_path = os.path.join(folder, 'labels.csv')\n",
    "            if os.path.exists(label_csv_path):\n",
    "                labels_df = pd.read_csv(label_csv_path)\n",
    "                # Assume labels_df has columns 'filename', 'event_class_true', 'rel_time_true'\n",
    "                label_row = labels_df[labels_df['filename'] == filename]\n",
    "                if not label_row.empty:\n",
    "                    result['event_class_true'] = int(label_row['event_class_true'].values[0])\n",
    "                    result['rel_time_true'] = float(label_row['rel_time_true'].values[0])\n",
    "            results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(results):\n",
    "    \"\"\"\n",
    "    Evaluate model predictions against ground truth and generate plots.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of dictionaries containing predictions and true labels.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Event Classification Evaluation\n",
    "    if 'event_class_true' in df.columns:\n",
    "        event_accuracy = accuracy_score(df['event_class_true'], df['event_class_pred'])\n",
    "        print(f\"Event Classification Accuracy: {event_accuracy:.4f}\")\n",
    "        # Generate Confusion Matrix\n",
    "        cm_display = ConfusionMatrixDisplay.from_predictions(df['event_class_true'], df['event_class_pred'])\n",
    "        plt.title('Event Classification Confusion Matrix')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Ground truth event classes not available for evaluation.\")\n",
    "    \n",
    "    # Arrival Time Evaluation\n",
    "    if 'rel_time_true' in df.columns:\n",
    "        time_mae = mean_absolute_error(df['rel_time_true'], df['rel_time_pred'])\n",
    "        print(f\"Arrival Time Mean Absolute Error (MAE): {time_mae:.4f} seconds\")\n",
    "        # Plot True vs. Predicted Arrival Times\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.scatter(df['rel_time_true'], df['rel_time_pred'], alpha=0.5)\n",
    "        plt.plot([df['rel_time_true'].min(), df['rel_time_true'].max()],\n",
    "                 [df['rel_time_true'].min(), df['rel_time_true'].max()], 'r--')\n",
    "        plt.xlabel('True Relative Arrival Time (s)')\n",
    "        plt.ylabel('Predicted Relative Arrival Time (s)')\n",
    "        plt.title('True vs. Predicted Relative Arrival Times')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Ground truth arrival times not available for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(results, output_csv_path):\n",
    "    \"\"\"\n",
    "    Save prediction results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of dictionaries containing predictions and file information.\n",
    "        output_csv_path (str): Path to save the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Results saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # ... [Training and saving the model code] ...\n",
    "\n",
    "    # Load the fine-tuned model\n",
    "    print(\"Loading the fine-tuned model...\")\n",
    "    model_path = 'fine_tuned_martian_seismic_cnn_full.pth'\n",
    "    model = load_trained_model(model_path)\n",
    "    \n",
    "    # Define test folders\n",
    "    test_folders = [\n",
    "        '../../data/marsquake_data/test/data',\n",
    "        '../../data/lunar_data/test/data/S12_GradeB',\n",
    "        '../../data/lunar_data/test/data/S15_GradeA',\n",
    "        '../../data/lunar_data/test/data/S15_GradeB',\n",
    "        '../../data/lunar_data/test/data/S16_GradeA',\n",
    "        '../../data/lunar_data/test/data/S16_GradeB'\n",
    "    ]\n",
    "    \n",
    "    # Predict on test data\n",
    "    print(\"Predicting on test data...\")\n",
    "    results = predict_on_test_data(model, test_folders)\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    print(\"Evaluating predictions...\")\n",
    "    evaluate_predictions(results)\n",
    "    \n",
    "    # Save results to CSV\n",
    "    output_csv_path = 'prediction_results.csv'\n",
    "    print(f\"Saving results to {output_csv_path}\")\n",
    "    save_results_to_csv(results, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
