{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy import read\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "\n",
    "# Set device to CPU\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy scikit-learn matplotlib seaborn plotly dash obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changed file paths to originals \n",
    "lunar_catalog_path = '../../data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv'\n",
    "lunar_data_directory = '../../data/lunar/training/data/S12_GradeA/'\n",
    "martian_data_directory = '../../data/mars/training/'\n",
    "save_dir = '../../data/lunar_preprocessed_images/'  # Directory to save preprocessed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rel_to_abs_time(start_time, time_rel):\n",
    "    \"\"\"\n",
    "    Convert relative time to absolute time using the trace start time.\n",
    "    \"\"\"\n",
    "    return (start_time + timedelta(seconds=float(time_rel))).strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "\n",
    "\n",
    "# Apply bandpass filter to seismic trace\n",
    "def apply_bandpass_filter(trace, sampling_rate, freqmin=0.5, freqmax=3.0):\n",
    "    sos = signal.butter(4, [freqmin, freqmax], btype='bandpass', fs=sampling_rate, output='sos')\n",
    "    return signal.sosfilt(sos, trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot filtered trace and spectrogram, mark arrival times, and save images\n",
    "def plot_and_save_trace_spectrogram(mseed_file, arrival_time_rel, save_dir, filename, combine_images=True):\n",
    "    # Read mseed file and extract the trace\n",
    "    st = read(mseed_file)\n",
    "    tr = st[0]\n",
    "    tr_data = tr.data\n",
    "    tr_times = tr.times()\n",
    "    sampling_rate = tr.stats.sampling_rate\n",
    "    starttime = tr.stats.starttime.datetime\n",
    "\n",
    "    # Convert relative time to absolute if provided\n",
    "    arrival_time_abs = convert_rel_to_abs_time(starttime, arrival_time_rel) if arrival_time_rel else None\n",
    "\n",
    "    # Apply bandpass filter to the trace data\n",
    "    filtered_trace = apply_bandpass_filter(tr_data, sampling_rate)\n",
    "\n",
    "    # Generate spectrogram\n",
    "    f, t, sxx = signal.spectrogram(filtered_trace, sampling_rate)\n",
    "\n",
    "    # Create figure for plotting trace and spectrogram\n",
    "    fig = plt.figure(figsize=(12, 10)) if combine_images else None\n",
    "\n",
    "    # Plot filtered trace\n",
    "    if combine_images or not combine_images:\n",
    "        ax1 = plt.subplot(3, 1, 1) if combine_images else plt.figure(figsize=(8, 6)).add_subplot(111)\n",
    "        ax1.plot(tr_times, filtered_trace, label='Filtered Trace')\n",
    "        if arrival_time_rel:\n",
    "            ax1.axvline(x=arrival_time_rel, color='red', label='Arrival Detection')\n",
    "        ax1.set_xlim([min(tr_times), max(tr_times)])\n",
    "        ax1.set_ylabel('Velocity (m/s)')\n",
    "        ax1.set_xlabel('Time (s)')\n",
    "        ax1.set_title(f'Filtered Seismic Trace\\nArrival Time: {arrival_time_abs}')\n",
    "        ax1.legend(loc='upper left')\n",
    "\n",
    "    # Plot spectrogram\n",
    "    if combine_images or not combine_images:\n",
    "        ax2 = plt.subplot(3, 1, 2) if combine_images else plt.figure(figsize=(8, 6)).add_subplot(111)\n",
    "        vals = ax2.pcolormesh(t, f, sxx, cmap='gray', shading='gouraud')\n",
    "        if arrival_time_rel:\n",
    "            ax2.axvline(x=arrival_time_rel, color='red')\n",
    "        ax2.set_xlim([min(t), max(t)])\n",
    "        ax2.set_ylabel('Frequency (Hz)')\n",
    "        ax2.set_xlabel('Time (s)')\n",
    "        cbar = plt.colorbar(vals, ax=ax2, orientation='horizontal')\n",
    "        cbar.set_label('Power ((m/s)^2/sqrt(Hz))')\n",
    "        ax2.set_title('Spectrogram')\n",
    "\n",
    "    # Save images: combined or separate\n",
    "    if combine_images:\n",
    "        save_path = os.path.join(save_dir, f\"{filename}_combined.png\")\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved combined image: {save_path}\")\n",
    "    else:\n",
    "        # Save the trace plot\n",
    "        trace_save_path = os.path.join(save_dir, f\"{filename}_trace.png\")\n",
    "        ax1.figure.tight_layout()\n",
    "        plt.savefig(trace_save_path, dpi=300)\n",
    "        plt.close(ax1.figure)\n",
    "        print(f\"Saved trace image: {trace_save_path}\")\n",
    "        \n",
    "        # Save the spectrogram plot\n",
    "        spectrogram_save_path = os.path.join(save_dir, f\"{filename}_spectrogram.png\")\n",
    "        ax2.figure.tight_layout()\n",
    "        plt.savefig(spectrogram_save_path, dpi=300)\n",
    "        plt.close(ax2.figure)\n",
    "        print(f\"Saved spectrogram image: {spectrogram_save_path}\")\n",
    "        \n",
    "        # Return the trace or spectrogram save path if not combined\n",
    "        save_path = trace_save_path  # Adjust as needed to return the trace or spectrogram path\n",
    "        # You can return both if needed, e.g., (trace_save_path, spectrogram_save_path)\n",
    "\n",
    "    return save_path  # Return the path of the saved image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_lunar_data(catalog, data_dir, save_dir, combine_images=True):\n",
    "    lunar_data, lunar_labels, lunar_arrival_times = [], [], []\n",
    "\n",
    "    print(f\"Processing Lunar Data: {len(catalog)} records found.\")\n",
    "    \n",
    "    for idx, row in catalog.iterrows():\n",
    "        filename = row['filename'] + '.mseed'\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            # Extract time_rel and time_abs\n",
    "            arrival_time_rel = row['time_rel(sec)']\n",
    "            arrival_time_abs = row['time_abs(%Y-%m-%dT%H:%M:%S.%f)']\n",
    "            \n",
    "            # Debug logging\n",
    "            print(f\"\\nProcessing file: {filename}\")\n",
    "            print(f\"Arrival Time (rel): {arrival_time_rel} seconds\")\n",
    "            print(f\"Arrival Time (abs): {arrival_time_abs}\")\n",
    "\n",
    "            # Generate and save spectrogram images\n",
    "            spectrogram_image_path = plot_and_save_trace_spectrogram(file_path, arrival_time_rel, save_dir, filename, combine_images)\n",
    "\n",
    "            # Append the image path (not .mseed path) to lunar_data\n",
    "            lunar_data.append(spectrogram_image_path)  # This should now contain the path to the saved image\n",
    "            \n",
    "            # Append labels and times for further training\n",
    "            lunar_labels.append(row['mq_type'])\n",
    "            lunar_arrival_times.append(arrival_time_abs)\n",
    "        else:\n",
    "            print(f\"File {filename} not found.\")\n",
    "    \n",
    "    # Ensure that lunar_data contains paths to saved images\n",
    "    return lunar_data, lunar_labels, lunar_arrival_times\n",
    "\n",
    "\n",
    "def preprocess_and_validate_martian_data(martian_data_directory, save_dir, combine_images=True):\n",
    "    print(\"Preprocessing Martian data (no labels)...\")\n",
    "    martian_data = preprocess_martian_data(martian_data_directory, save_dir, combine_images)\n",
    "\n",
    "    if len(martian_data) > 0:\n",
    "        print(f\"Martian Data: {len(martian_data)} files found.\")\n",
    "        for i in range(min(5, len(martian_data))):\n",
    "            img_path = martian_data[i]\n",
    "            if os.path.exists(img_path) and img_path.endswith('.png'):\n",
    "                print(f\"Valid Martian image path: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Invalid Martian image path or file does not exist: {img_path}\")\n",
    "    else:\n",
    "        print(\"Error: No Martian data found.\")\n",
    "    \n",
    "    return martian_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpectrogramCNN, self).__init__()\n",
    "        # CNN layers for spectrogram feature extraction\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)  # For grayscale spectrograms\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Add a placeholder for the fully connected input size\n",
    "        self.fc_input_size = None  # To be calculated dynamically\n",
    "        \n",
    "        # Define fully connected layers (we'll initialize them later)\n",
    "        self.fc1 = None\n",
    "        self.fc_event = nn.Linear(128, 3)  # For event classification (3 classes)\n",
    "        self.fc_time = nn.Linear(128, 1)   # For arrival time prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Initialize fully connected layers dynamically if not already initialized\n",
    "        if self.fc1 is None:\n",
    "            self.fc_input_size = x.size(1)\n",
    "            self.fc1 = nn.Linear(self.fc_input_size, 128)\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        \n",
    "        # Separate heads for classification and regression\n",
    "        event_output = self.fc_event(x)  # Output for event classification\n",
    "        time_output = self.fc_time(x)    # Output for arrival time prediction\n",
    "        \n",
    "        return event_output, time_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_training(image_files, labels, time_labels, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "    \n",
    "    image_tensors = []\n",
    "    for img in image_files:\n",
    "        # Verify that the file exists and is a .png image\n",
    "        if os.path.exists(img) and img.endswith('.png'):\n",
    "            try:\n",
    "                img_tensor = transform(Image.open(img))\n",
    "                image_tensors.append(img_tensor)\n",
    "                print(f\"Loaded image: {img}\")  # Debug print for loaded images\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "        else:\n",
    "            print(f\"Image file not found or invalid: {img}\")  # If the file is not found or not a .png\n",
    "\n",
    "    # Convert the list of image tensors into a single tensor\n",
    "    if image_tensors:\n",
    "        X_tensor = torch.stack(image_tensors)\n",
    "        y_event_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        y_time_tensor = torch.tensor(time_labels, dtype=torch.float32)\n",
    "        \n",
    "        dataset = TensorDataset(X_tensor, y_event_tensor, y_time_tensor)\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    else:\n",
    "        print(\"No valid images found.\")\n",
    "        return None\n",
    "\n",
    "# Train model\n",
    "def train_model(model, train_loader, criterion_event, criterion_time, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, event_labels, time_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            event_output, time_output = model(inputs)\n",
    "            loss_event = criterion_event(event_output, event_labels)\n",
    "            loss_time = criterion_time(time_output.squeeze(), time_labels)\n",
    "            loss = loss_event + loss_time\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-training for martian data (pseudo-labeling)\n",
    "def self_train_on_martian_data(model, martian_data_loader, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs in martian_data_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through the model (get pseudo-labels)\n",
    "            event_output, time_output = model(inputs)\n",
    "            _, pseudo_labels = torch.max(event_output, 1)\n",
    "\n",
    "            # For now, we do not have ground truth for martian data, so we only optimize on pseudo-labels\n",
    "            loss_event = nn.CrossEntropyLoss()(event_output, pseudo_labels)\n",
    "            loss_time = nn.MSELoss()(time_output, torch.zeros_like(time_output))  # Zero as placeholder\n",
    "\n",
    "            loss = loss_event + loss_time\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Self-training Epoch {epoch+1}, Loss: {running_loss / len(martian_data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model architecture and weights\n",
    "def save_model_artifacts(model, model_name='seismic_cnn_model'):\n",
    "    # 1. Save the model architecture (artifact) in a JSON or similar format\n",
    "    model_architecture = {\n",
    "        'input_size': model.conv1.in_channels,\n",
    "        'conv_layers': [\n",
    "            {\n",
    "                'in_channels': model.conv1.in_channels, \n",
    "                'out_channels': model.conv1.out_channels, \n",
    "                'kernel_size': model.conv1.kernel_size, \n",
    "                'stride': model.conv1.stride, \n",
    "                'padding': model.conv1.padding\n",
    "            },\n",
    "            {\n",
    "                'in_channels': model.conv2.in_channels, \n",
    "                'out_channels': model.conv2.out_channels, \n",
    "                'kernel_size': model.conv2.kernel_size, \n",
    "                'stride': model.conv2.stride, \n",
    "                'padding': model.conv2.padding\n",
    "            }\n",
    "        ],\n",
    "        'fc_layers': []\n",
    "    }\n",
    "\n",
    "    # If fc1 has been initialized, save its architecture\n",
    "    if model.fc1 is not None:\n",
    "        model_architecture['fc_layers'].append({\n",
    "            'in_features': model.fc1.in_features, \n",
    "            'out_features': model.fc1.out_features\n",
    "        })\n",
    "    \n",
    "    # Save the event classification and time regression layers\n",
    "    if hasattr(model, 'fc_event'):\n",
    "        model_architecture['fc_layers'].append({\n",
    "            'in_features': model.fc_event.in_features, \n",
    "            'out_features': model.fc_event.out_features  # Event classification layer\n",
    "        })\n",
    "    if hasattr(model, 'fc_time'):\n",
    "        model_architecture['fc_layers'].append({\n",
    "            'in_features': model.fc_time.in_features, \n",
    "            'out_features': model.fc_time.out_features  # Time regression layer\n",
    "        })\n",
    "\n",
    "    # Save model architecture to JSON\n",
    "    with open(f'{model_name}_architecture.json', 'w') as f:\n",
    "        json.dump(model_architecture, f, indent=4)\n",
    "    print(f\"Model architecture saved to {model_name}_architecture.json\")\n",
    "\n",
    "    # 2. Save the model weights (only the parameters)\n",
    "    torch.save(model.state_dict(), f'{model_name}_weights.pth')\n",
    "    print(f\"Model weights saved to {model_name}_weights.pth\")\n",
    "\n",
    "    # 3. Save the full model (architecture + weights)\n",
    "    torch.save(model, f'{model_name}_full.pth')\n",
    "    print(f\"Full model saved to {model_name}_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lunar_catalog(lunar_catalog_path):\n",
    "    print(f\"Loading lunar catalog from: {lunar_catalog_path}\")\n",
    "    lunar_catalog = pd.read_csv(lunar_catalog_path)\n",
    "    return lunar_catalog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels_and_convert_time(lunar_labels, lunar_arrival_times):\n",
    "    print(\"Encoding lunar labels into integers...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    lunar_labels_encoded = label_encoder.fit_transform(lunar_labels)\n",
    "\n",
    "    print(\"Converting arrival times to relative times (seconds)...\")\n",
    "    lunar_arrival_times_numeric = [\n",
    "        (pd.to_datetime(time) - pd.to_datetime(lunar_arrival_times[0])).total_seconds() for time in lunar_arrival_times\n",
    "    ]\n",
    "\n",
    "    print(f\"Numeric Lunar Arrival Times: {lunar_arrival_times_numeric[:5]}\")\n",
    "    \n",
    "    return lunar_labels_encoded, lunar_arrival_times_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lunar_data_for_training(lunar_data, lunar_labels_encoded, lunar_arrival_times_numeric):\n",
    "    print(\"Splitting lunar data into training and validation sets...\")\n",
    "    X_train, X_val, y_event_train, y_event_val, y_time_train, y_time_val = train_test_split(\n",
    "        lunar_data, lunar_labels_encoded, lunar_arrival_times_numeric, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"Preparing DataLoader for lunar training data...\")\n",
    "    train_loader = prepare_data_for_training(X_train, y_event_train, y_time_train)\n",
    "    val_loader = prepare_data_for_training(X_val, y_event_val, y_time_val)\n",
    "\n",
    "    if train_loader is not None:\n",
    "        print(\"DataLoader successfully created for training.\")\n",
    "    else:\n",
    "        print(\"Error: DataLoader creation failed.\")\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_and_train_model(train_loader):\n",
    "    print(\"Initializing SpectrogramCNN model...\")\n",
    "    model = SpectrogramCNN()\n",
    "    criterion_event = nn.CrossEntropyLoss()\n",
    "    criterion_time = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    if train_loader:\n",
    "        print(\"Training model on lunar data...\")\n",
    "        train_model(model, train_loader, criterion_event, criterion_time, optimizer)\n",
    "    else:\n",
    "        print(\"Error: Training skipped due to invalid DataLoader.\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_validate_lunar_data(lunar_catalog, lunar_data_directory, save_dir, combine_images=True):\n",
    "    print(\"Preprocessing lunar data...\")\n",
    "    lunar_data, lunar_labels, lunar_arrival_times = preprocess_lunar_data(\n",
    "        lunar_catalog, lunar_data_directory, save_dir, combine_images\n",
    "    )\n",
    "\n",
    "    print(f\"Lunar Data: {len(lunar_data)} images, Labels: {len(lunar_labels)}, Arrival Times: {len(lunar_arrival_times)}\")\n",
    "\n",
    "    if len(lunar_data) > 0:\n",
    "        for i in range(min(5, len(lunar_data))):\n",
    "            img_path = lunar_data[i]\n",
    "            if os.path.exists(img_path) and img_path.endswith('.png'):\n",
    "                print(f\"Valid image path: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Invalid image path or file does not exist: {img_path}\")\n",
    "    else:\n",
    "        print(\"Error: No lunar image data found.\")\n",
    "    \n",
    "    return lunar_data, lunar_labels, lunar_arrival_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_validate_martian_data(martian_data_directory, save_dir, combine_images=True):\n",
    "    print(\"Preprocessing Martian data (no labels)...\")\n",
    "    martian_data = preprocess_martian_data(martian_data_directory, save_dir, combine_images)\n",
    "\n",
    "    if len(martian_data) > 0:\n",
    "        print(f\"Martian Data: {len(martian_data)} files found.\")\n",
    "        for i in range(min(5, len(martian_data))):\n",
    "            img_path = martian_data[i]\n",
    "            if os.path.exists(img_path) and img_path.endswith('.png'):\n",
    "                print(f\"Valid Martian image path: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Invalid Martian image path or file does not exist: {img_path}\")\n",
    "    else:\n",
    "        print(\"Error: No Martian data found.\")\n",
    "    \n",
    "    return martian_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_train_on_martian_data(model, martian_data):\n",
    "    print(\"Preparing DataLoader for Martian data (self-training)...\")\n",
    "    martian_data_loader = prepare_data_for_training(\n",
    "        martian_data, labels=[0] * len(martian_data), time_labels=[0] * len(martian_data)  # Placeholder labels\n",
    "    )\n",
    "\n",
    "    if martian_data_loader:\n",
    "        print(\"Self-training model on Martian data...\")\n",
    "        self_train_on_martian_data(model, martian_data_loader, optimizer)\n",
    "    else:\n",
    "        print(\"Error: Self-training skipped due to invalid DataLoader for Martian data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load the lunar catalog\n",
    "    print(\"Loading lunar catalog...\")\n",
    "    lunar_catalog = load_lunar_catalog(lunar_catalog_path)\n",
    "    \n",
    "    # Preprocess and validate lunar data\n",
    "    print(\"Preprocessing and validating lunar data...\")\n",
    "    lunar_data, lunar_labels, lunar_arrival_times = preprocess_and_validate_lunar_data(\n",
    "        lunar_catalog, lunar_data_directory, save_dir, combine_images=True\n",
    "    )\n",
    "    \n",
    "    # Encode labels and convert arrival times to numeric values\n",
    "    print(\"Encoding labels and converting arrival times...\")\n",
    "    lunar_labels_encoded, lunar_arrival_times_numeric = encode_labels_and_convert_time(\n",
    "        lunar_labels, lunar_arrival_times\n",
    "    )\n",
    "    \n",
    "    # Prepare DataLoader for lunar data training\n",
    "    print(\"Preparing DataLoader for lunar training and validation sets...\")\n",
    "    train_loader, val_loader = prepare_lunar_data_for_training(\n",
    "        lunar_data, lunar_labels_encoded, lunar_arrival_times_numeric\n",
    "    )\n",
    "    \n",
    "    # Initialize and train the model on lunar data\n",
    "    print(\"Initializing and training the model on lunar data...\")\n",
    "    model = initialize_and_train_model(train_loader, val_loader)\n",
    "    \n",
    "    # Preprocess and validate martian data for self-training\n",
    "    print(\"Preprocessing and validating Martian data...\")\n",
    "    martian_data = preprocess_and_validate_martian_data(martian_data_directory, save_dir, combine_images=True)\n",
    "    \n",
    "    # Self-train the model using Martian data\n",
    "    print(\"Self-training the model on Martian data...\")\n",
    "    self_train_on_martian_data(model, martian_data)\n",
    "    \n",
    "    # Save the trained model\n",
    "    print(\"Saving the trained model...\")\n",
    "    save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lunar catalog...\n",
      "Loading lunar catalog from: ../../data/lunar/training/catalogs/apollo12_catalog_GradeA_final.csv\n",
      "Preprocessing and validating lunar data...\n",
      "Preprocessing lunar data...\n",
      "Processing Lunar Data: 76 records found.\n",
      "\n",
      "Processing file: xa.s12.00.mhz.1970-01-19HR00_evid00002.mseed\n",
      "Arrival Time (rel): 73500.0 seconds\n",
      "Arrival Time (abs): 1970-01-19T20:25:00.000000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unknown format for file ../../data/lunar/training/data/S12_GradeA/xa.s12.00.mhz.1970-01-19HR00_evid00002.mseed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[244], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[243], line 8\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Preprocess and validate lunar data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing and validating lunar data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m lunar_data, lunar_labels, lunar_arrival_times \u001b[38;5;241m=\u001b[39m preprocess_and_validate_lunar_data(\n\u001b[0;32m      9\u001b[0m     lunar_catalog, lunar_data_directory, save_dir, combine_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Encode labels and convert arrival times to numeric values\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoding labels and converting arrival times...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[240], line 3\u001b[0m, in \u001b[0;36mpreprocess_and_validate_lunar_data\u001b[1;34m(lunar_catalog, lunar_data_directory, save_dir, combine_images)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_and_validate_lunar_data\u001b[39m(lunar_catalog, lunar_data_directory, save_dir, combine_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing lunar data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     lunar_data, lunar_labels, lunar_arrival_times \u001b[38;5;241m=\u001b[39m preprocess_lunar_data(\n\u001b[0;32m      4\u001b[0m         lunar_catalog, lunar_data_directory, save_dir, combine_images\n\u001b[0;32m      5\u001b[0m     )\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLunar Data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lunar_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images, Labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lunar_labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Arrival Times: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(lunar_arrival_times)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lunar_data) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[231], line 21\u001b[0m, in \u001b[0;36mpreprocess_lunar_data\u001b[1;34m(catalog, data_dir, save_dir, combine_images)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArrival Time (abs): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marrival_time_abs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Generate and save spectrogram images\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m spectrogram_image_path \u001b[38;5;241m=\u001b[39m plot_and_save_trace_spectrogram(file_path, arrival_time_rel, save_dir, filename, combine_images)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Append the image path (not .mseed path) to lunar_data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m lunar_data\u001b[38;5;241m.\u001b[39mappend(spectrogram_image_path)  \u001b[38;5;66;03m# This should now contain the path to the saved image\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[230], line 4\u001b[0m, in \u001b[0;36mplot_and_save_trace_spectrogram\u001b[1;34m(mseed_file, arrival_time_rel, save_dir, filename, combine_images)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_and_save_trace_spectrogram\u001b[39m(mseed_file, arrival_time_rel, save_dir, filename, combine_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Read mseed file and extract the trace\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     st \u001b[38;5;241m=\u001b[39m read(mseed_file)\n\u001b[0;32m      5\u001b[0m     tr \u001b[38;5;241m=\u001b[39m st[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m     tr_data \u001b[38;5;241m=\u001b[39m tr\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\util\\decorator.py:297\u001b[0m, in \u001b[0;36mmap_example_filename.<locals>._map_example_filename\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m                     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\stream.py:208\u001b[0m, in \u001b[0;36mread\u001b[1;34m(pathname_or_url, format, headonly, starttime, endtime, nearest_sample, dtype, apply_calib, check_compression, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m     st \u001b[38;5;241m=\u001b[39m _create_example_stream(headonly\u001b[38;5;241m=\u001b[39mheadonly)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     st \u001b[38;5;241m=\u001b[39m _generic_reader(pathname_or_url, _read, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pathname_or_url, Path):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\util\\base.py:658\u001b[0m, in \u001b[0;36m_generic_reader\u001b[1;34m(pathname_or_url, callback_func, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mhas_magic(pathname) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(pathname)\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory\u001b[39m\u001b[38;5;124m\"\u001b[39m, pathname)\n\u001b[1;32m--> 658\u001b[0m generic \u001b[38;5;241m=\u001b[39m callback_func(pathnames[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pathnames) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m pathnames[\u001b[38;5;241m1\u001b[39m:]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\util\\decorator.py:208\u001b[0m, in \u001b[0;36muncompress_file\u001b[1;34m(func, filename, *args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m                 result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# no compressions\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(filename, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\stream.py:251\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filename, format, headonly, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;129m@uncompress_file\u001b[39m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read\u001b[39m(filename, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headonly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m    Read a single file into a ObsPy Stream object.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     stream, \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m _read_from_plugin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwaveform\u001b[39m\u001b[38;5;124m'\u001b[39m, filename, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    252\u001b[0m                                        headonly\u001b[38;5;241m=\u001b[39mheadonly, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# set _format identifier for each element\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trace \u001b[38;5;129;01min\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\obspy\\core\\util\\base.py:403\u001b[0m, in \u001b[0;36m_read_from_plugin\u001b[1;34m(plugin_type, filename, format, **kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown format for file \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# format given via argument\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mupper()\n",
      "\u001b[1;31mTypeError\u001b[0m: Unknown format for file ../../data/lunar/training/data/S12_GradeA/xa.s12.00.mhz.1970-01-19HR00_evid00002.mseed"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.abspath(lunar_catalog_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Assuming the images are already saved in a directory\n",
    "def load_existing_images(image_dir):\n",
    "    \"\"\"\n",
    "    Load the paths of pre-generated images from the given directory.\n",
    "    \"\"\"\n",
    "    image_files = []\n",
    "    for root, _, files in os.walk(image_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'):\n",
    "                image_files.append(os.path.join(root, file))\n",
    "    return image_files\n",
    "\n",
    "def preprocess_lunar_data(lunar_data_directory):\n",
    "    \"\"\"\n",
    "    Skip generating images and directly load pre-generated lunar images.\n",
    "    \"\"\"\n",
    "    print(f\"Loading pre-generated lunar images from {lunar_data_directory}...\")\n",
    "    lunar_images = load_existing_images(lunar_data_directory)\n",
    "    print(f\"{len(lunar_images)} lunar images loaded.\")\n",
    "    return lunar_images\n",
    "\n",
    "def preprocess_martian_data(martian_data_directory):\n",
    "    \"\"\"\n",
    "    Skip generating images and directly load pre-generated Martian images.\n",
    "    \"\"\"\n",
    "    print(f\"Loading pre-generated Martian images from {martian_data_directory}...\")\n",
    "    martian_images = load_existing_images(martian_data_directory)\n",
    "    print(f\"{len(martian_images)} Martian images loaded.\")\n",
    "    return martian_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def main():\n",
    "    # Define the path where preprocessed images are stored\n",
    "    lunar_data_images_dir = '../../model/model_output/lunar_preprocessed_images/'\n",
    "    # Load pre-generated lunar images\n",
    "    print(f\"Loading pre-generated lunar data from: {lunar_data_images_dir}\")\n",
    "    \n",
    "    # List all image files in the directory\n",
    "    lunar_data_images = [os.path.join(lunar_data_images_dir, f) for f in os.listdir(lunar_data_images_dir) if f.endswith('.png')]\n",
    "    \n",
    "    # Debugging to ensure consistent data lengths\n",
    "    print(f\"Lunar Data: {len(lunar_data_images)} images\")\n",
    "\n",
    "    # Confirm that the image files exist and are correct\n",
    "    if len(lunar_data_images) > 0:\n",
    "        for i in range(min(5, len(lunar_data_images))):  # Checking the first 5 file paths\n",
    "            img_path = lunar_data_images[i]\n",
    "            if os.path.exists(img_path) and img_path.endswith('.png'):\n",
    "                print(f\"Valid image path: {img_path}\")\n",
    "            else:\n",
    "                print(f\"Invalid image path or file does not exist: {img_path}\")\n",
    "    else:\n",
    "        print(\"Error: No lunar image data found. Skipping the training process.\")\n",
    "        return  # Exit the function early if no data is found\n",
    "\n",
    "    # Assuming lunar labels and arrival times are stored or generated elsewhere\n",
    "    # Placeholder for labels and arrival times, adjust according to your logic\n",
    "    lunar_labels_encoded = [0] * len(lunar_data_images)  # Placeholder labels\n",
    "    lunar_arrival_times_numeric = [0] * len(lunar_data_images)  # Placeholder arrival times\n",
    "\n",
    "    # Split data into training and validation sets\n",
    "    print(\"Splitting lunar data into training and validation sets...\")\n",
    "    X_train, X_val, y_event_train, y_event_val, y_time_train, y_time_val = train_test_split(\n",
    "        lunar_data_images, lunar_labels_encoded, lunar_arrival_times_numeric, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Convert processed lunar data to DataLoader for training\n",
    "    print(\"Preparing DataLoader for lunar training data...\")\n",
    "    train_loader = prepare_data_for_training(X_train, y_event_train, y_time_train)\n",
    "    val_loader = prepare_data_for_training(X_val, y_event_val, y_time_val)\n",
    "\n",
    "    # Check if the data loader is valid\n",
    "    if train_loader is not None:\n",
    "        print(\"DataLoader successfully created for training.\")\n",
    "    else:\n",
    "        print(\"Error: DataLoader creation failed.\")\n",
    "\n",
    "    # Initialize the model and define loss functions and optimizer\n",
    "    print(\"Initializing SpectrogramCNN model...\")\n",
    "    model = SpectrogramCNN()\n",
    "    criterion_event = nn.CrossEntropyLoss()\n",
    "    criterion_time = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model on lunar data\n",
    "    print(\"Training model on lunar data...\")\n",
    "    if train_loader:\n",
    "        train_model(model, train_loader, criterion_event, criterion_time, optimizer)\n",
    "    else:\n",
    "        print(\"Error: Training skipped due to invalid DataLoader.\")\n",
    "\n",
    "    # Save the trained model\n",
    "    print(\"Saving the trained model...\")\n",
    "    save_model_artifacts(model)\n",
    "    print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Martian Data, Save Images and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_martian_data(data_dir, save_dir, combine_images=True):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    martian_images = []\n",
    "    martian_arrival_times = []\n",
    "\n",
    "    # List all .mseed files in the data directory\n",
    "    mseed_files = [f for f in os.listdir(data_dir) if f.endswith('.mseed')]\n",
    "\n",
    "    if len(mseed_files) == 0:\n",
    "        print(\"No .mseed files found in the directory.\")\n",
    "        return martian_images, martian_arrival_times\n",
    "\n",
    "    # Iterate over each .mseed file\n",
    "    for filename in mseed_files:\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "        # Derive the corresponding CSV file path from the .mseed filename\n",
    "        csv_file_name = filename.replace('.mseed', '.csv')\n",
    "        csv_file_path = os.path.join(data_dir, csv_file_name)\n",
    "\n",
    "        # Ensure the CSV file exists before processing\n",
    "        if not os.path.exists(csv_file_path):\n",
    "            print(f\"CSV file not found for {filename}: {csv_file_path}\")\n",
    "            continue\n",
    "\n",
    "        # Read the CSV file to get the rel_time (relative time in seconds)\n",
    "        try:\n",
    "            csv_data = pd.read_csv(csv_file_path)\n",
    "            if 'rel_time(sec)' not in csv_data.columns:\n",
    "                print(f\"CSV does not contain 'rel_time(sec)': {csv_file_path}\")\n",
    "                continue\n",
    "            arrival_time_rel = csv_data['rel_time(sec)'].iloc[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file {csv_file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Process and generate spectrogram\n",
    "        try:\n",
    "            image_path = plot_and_save_trace_spectrogram(file_path, arrival_time_rel, save_dir, filename, combine_images)\n",
    "            martian_images.append(image_path)\n",
    "            martian_arrival_times.append(arrival_time_rel)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "    \n",
    "    return martian_images, martian_arrival_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_train_on_martian_data(model, data_loader, optimizer, criterion_event, criterion_time, num_epochs=10):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, event_labels, time_labels) in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            event_output, time_output = model(images)\n",
    "            loss_event = criterion_event(event_output, event_labels)\n",
    "            loss_time = criterion_time(time_output.squeeze(), time_labels)\n",
    "            total_loss = loss_event + loss_time\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(data_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    event_preds, time_preds, event_true, time_true = [], [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, event_labels, time_labels in data_loader:\n",
    "            images, event_labels, time_labels = images.to(device), event_labels.to(device), time_labels.to(device)\n",
    "\n",
    "            event_output, time_output = model(images)\n",
    "\n",
    "            # Gather predictions and true values for validation metrics\n",
    "            _, event_pred_classes = torch.max(event_output, 1)\n",
    "            event_preds.extend(event_pred_classes.cpu().numpy())\n",
    "            time_preds.extend(time_output.cpu().numpy())\n",
    "            event_true.extend(event_labels.cpu().numpy())\n",
    "            time_true.extend(time_labels.cpu().numpy())\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    event_accuracy = accuracy_score(event_true, event_preds)\n",
    "    time_mae = mean_absolute_error(time_true, time_preds)\n",
    "\n",
    "    print(f\"Validation Event Accuracy: {event_accuracy:.4f}\")\n",
    "    print(f\"Validation Time MAE: {time_mae:.4f}\")\n",
    "\n",
    "    # Optionally: plot loss curves, accuracy, confusion matrix, etc.\n",
    "    plot_metrics(event_true, event_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "def plot_metrics(event_true, event_preds):\n",
    "    # Example: Plot confusion matrix (for event classification)\n",
    "    ConfusionMatrixDisplay.from_predictions(event_true, event_preds)\n",
    "    plt.title(\"Confusion Matrix for Event Classification\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Optionally: You can plot loss/accuracy curves here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "martian_image_dir = '../../model/model_output/martian_preprocessed_images/'\n",
    "martian_data_dir = '../../data/marsquake_data/training/data/'\n",
    "martian_catalog_path = '../../data/marsquake_data/training/catalogs/Mars_InSight_training_catalog.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Preprocess and load Martian data\n",
    "    print(\"Preprocessing Martian data...\")\n",
    "    martian_data_images, martian_arrival_times = preprocess_martian_data(martian_data_dir, save_dir, combine_images=True)\n",
    "\n",
    "    # Placeholder labels for Martian data (self-training)\n",
    "    martian_labels = [0] * len(martian_data_images)  # Placeholder labels\n",
    "    \n",
    "    print(\"Loading the pre-trained model...\")\n",
    "    model = SpectrogramCNN()\n",
    "    state_dict = torch.load('seismic_cnn_model_weights.pth')\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    # Define the loss functions and optimizer\n",
    "    print(\"Defining loss functions and optimizer...\")\n",
    "    criterion_event = nn.CrossEntropyLoss()\n",
    "    criterion_time = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Prepare DataLoader for Martian data (self-training)\n",
    "    print(\"Self-training model on Martian data...\")\n",
    "    martian_data_loader = prepare_data_for_training(martian_data_images, martian_labels, martian_arrival_times)\n",
    "\n",
    "    if martian_data_loader:\n",
    "        self_train_on_martian_data(model, martian_data_loader, optimizer, criterion_event, criterion_time)\n",
    "    else:\n",
    "        print(\"Error: Self-training skipped due to invalid DataLoader for Martian data.\")\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    save_model_artifacts(model, model_name='fine_tuned_martian_seismic_cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
